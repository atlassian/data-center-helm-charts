---
# Source: confluence/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: unittest-confluence
  labels:
    helm.sh/chart: confluence-1.22.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "8.5.17"
    app.kubernetes.io/managed-by: Helm
---
# Source: confluence/templates/config-jvm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: unittest-confluence-jvm-config
  labels:
    helm.sh/chart: confluence-1.22.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "8.5.17"
    app.kubernetes.io/managed-by: Helm
data:
  additional_jvm_args: >-
    -Dconfluence.cluster.hazelcast.listenPort=5701
    -Dsynchrony.service.url=https:///synchrony/v1
    -Dsynchrony.by.default.enable.collab.editing.if.manually.managed=true
    -Dconfluence.clusterNodeName.useHostname=true
    -Datlassian.logging.cloud.enabled=false
    -XX:ActiveProcessorCount=2    
  max_heap: 1g
  min_heap: 1g
  reserved_code_cache: 256m
---
# Source: confluence/templates/configmap-jmx-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: unittest-confluence-jmx-config
  labels:
    helm.sh/chart: confluence-1.22.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "8.5.17"
    app.kubernetes.io/managed-by: Helm
data:
  jmx-config.yaml: |
    rules:
    - pattern: '(java.lang)<type=(\w+)><>(\w+):'
      name: java_lang_$2_$3
    - pattern: 'java.lang<type=Memory><HeapMemoryUsage>(\w+)'
      name: java_lang_Memory_HeapMemoryUsage_$1
    - pattern: 'java.lang<name=G1 (\w+) Generation, type=GarbageCollector><>(\w+)'
      name: java_lang_G1_$1_Generation_$2
    - pattern: '.*'
---
# Source: confluence/templates/configmap-values-analytics.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: unittest-confluence-helm-values
  labels:
    helm.sh/chart: confluence-1.22.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "8.5.17"
    app.kubernetes.io/managed-by: Helm
data:
  values.yaml: |
    additionalConfigMaps: []
    additionalContainers: []
    additionalFiles: []
    additionalHosts:
    - hostnames:
      - test.example.com
      ip: 192.168.1.1
    additionalInitContainers: []
    additionalLabels: {}
    affinity: {}
    atlassianAnalyticsAndSupport:
      analytics:
        enabled: false
      helmValues:
        enabled: true
    common:
      global: {}
    confluence:
      accessLog:
        enabled: true
        localHomeSubPath: logs
        mountPath: /opt/atlassian/confluence/logs
      additionalAnnotations:
        argocd.argoproj.io/sync-wave: "10"
      additionalBundledPlugins: []
      additionalCertificates:
        customCmd: null
        initContainer:
          resources: {}
        secretList: []
        secretName: null
      additionalEnvironmentVariables: []
      additionalJvmArgs: []
      additionalLibraries: []
      additionalPorts: []
      additionalVolumeClaimTemplates: []
      additionalVolumeMounts: []
      clustering:
        enabled: false
        usePodNameAsClusterNodeName: true
      containerSecurityContext: {}
      forceConfigUpdate: false
      hazelcastService:
        annotations: {}
        enabled: false
        port: 5701
        type: ClusterIP
      jvmDebug:
        enabled: false
      license:
        secretKey: license-key
        secretName: null
      livenessProbe:
        customProbe: {}
        enabled: false
        failureThreshold: 12
        initialDelaySeconds: 60
        periodSeconds: 5
        timeoutSeconds: 1
      ports:
        hazelcast: 5701
        http: 8090
      postStart:
        command: null
      readinessProbe:
        customProbe: {}
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 10
        periodSeconds: 5
        timeoutSeconds: 1
      resources:
        container:
          requests:
            cpu: "2"
            memory: 2G
        jvm:
          maxHeap: 1g
          minHeap: 1g
          reservedCodeCache: 256m
      s3AttachmentsStorage:
        bucketName: null
        bucketRegion: null
        endpointOverride: null
      securityContext:
        fsGroup: 2002
      securityContextEnabled: true
      seraphConfig:
        autoLoginCookieAge: "1209600"
        generateByHelm: false
      service:
        annotations: {}
        contextPath: null
        loadBalancerIP: null
        port: 80
        sessionAffinity: None
        sessionAffinityConfig:
          clientIP:
            timeoutSeconds: null
        type: ClusterIP
      setPermissions: true
      shutdown:
        command: /shutdown-wait.sh
        terminationGracePeriodSeconds: 25
      startupProbe:
        enabled: false
        failureThreshold: 120
        initialDelaySeconds: 60
        periodSeconds: 5
      tomcatConfig:
        acceptCount: "100"
        connectionTimeout: "20000"
        customServerXml: ""
        debug: "0"
        enableLookups: "false"
        generateByHelm: false
        maxHttpHeaderSize: "8192"
        maxThreads: "100"
        mgmtPort: "8000"
        minSpareThreads: "10"
        port: "8090"
        protocol: org.apache.coyote.http11.Http11NioProtocol
        proxyInternalIps: null
        proxyName: null
        proxyPort: null
        redirectPort: "8443"
        scheme: null
        secure: null
        stuckThreadDetectionValveThreshold: "60"
        trustedProxies: null
        uriEncoding: UTF-8
      topologySpreadConstraints: []
      umask: "0022"
      useHelmReleaseNameAsContainerName: false
    database:
      credentials:
        passwordSecretKey: password
        secretName: null
        usernameSecretKey: username
      type: null
      url: null
    fluentd:
      command: null
      customConfigFile: false
      elasticsearch:
        enabled: true
        hostname: elasticsearch
        indexNamePrefix: confluence
      enabled: false
      extraVolumes: []
      fluentdCustomConfig: {}
      httpPort: 9880
      imageRepo: fluent/fluentd-kubernetes-daemonset
      imageTag: v1.11.5-debian-elasticsearch7-1.2
      resources: {}
    image:
      pullPolicy: IfNotPresent
      repository: atlassian/confluence
      tag: ""
    ingress:
      annotations: {}
      className: nginx
      create: false
      host: null
      https: true
      maxBodySize: 250m
      nginx: true
      openShiftRoute: false
      path: null
      proxyConnectTimeout: 60
      proxyReadTimeout: 60
      proxySendTimeout: 60
      routeHttpHeaders: {}
      tlsSecretName: null
    monitoring:
      exposeJmxMetrics: true
      fetchJmxExporterJar: true
      grafana:
        createDashboards: false
        dashboardAnnotations: {}
        dashboardLabels: {}
      jmxExporterCustomConfig: {}
      jmxExporterCustomJarLocation: null
      jmxExporterImageRepo: bitnami/jmx-exporter
      jmxExporterImageTag: 0.18.0
      jmxExporterInitContainer:
        customSecurityContext: {}
        jmxJarLocation: null
        resources: {}
        runAsRoot: true
      jmxExporterPort: 9999
      jmxExporterPortType: ClusterIP
      jmxServiceAnnotations: {}
      serviceMonitor:
        create: false
        prometheusLabelSelector: {}
        scrapeIntervalSeconds: 30
    nodeSelector: {}
    opensearch:
      credentials:
        createSecret: true
        existingSecretRef:
          name: null
      enabled: false
      envFrom:
      - secretRef:
          name: opensearch-initial-password
      extraEnvs:
      - name: plugins.security.ssl.http.enabled
        value: "false"
      persistence:
        size: 10Gi
      resources:
        requests:
          cpu: 1
          memory: 1Gi
      singleNode: true
    openshift:
      runWithRestrictedSCC: false
    ordinals:
      enabled: false
      start: 0
    podAnnotations: {}
    podDisruptionBudget:
      annotations: {}
      enabled: false
      labels: {}
      maxUnavailable: null
      minAvailable: null
    podLabels: {}
    priorityClassName: high
    replicaCount: 1
    serviceAccount:
      annotations: {}
      clusterRole:
        create: false
        name: null
      clusterRoleBinding:
        create: false
        name: null
      create: true
      eksIrsa:
        roleArn: null
      imagePullSecrets: []
      name: null
      role:
        create: true
      roleBinding:
        create: true
    synchrony:
      additionalAnnotations:
        argocd.argoproj.io/sync-wave: "10"
      additionalCertificates:
        customCmd: null
        initContainer:
          resources: {}
        secretList: []
        secretName: null
      additionalJvmArgs: []
      additionalLibraries: []
      additionalPorts: []
      additionalVolumeMounts: []
      containerSecurityContext: {}
      enabled: true
      ingress:
        annotations: null
        path: null
        pathType: null
      podAnnotations: {}
      ports:
        hazelcast: 5701
        http: 8091
      readinessProbe:
        failureThreshold: 10
        healthcheckPath: /synchrony/heartbeat
        initialDelaySeconds: 5
        periodSeconds: 1
      replicaCount: 1
      resources:
        container:
          requests:
            cpu: "2"
            memory: 2.5G
        jvm:
          maxHeap: 2g
          minHeap: 1g
          stackSize: 2048k
      securityContext:
        fsGroup: 2002
      securityContextEnabled: true
      service:
        annotations: {}
        loadBalancerIP: null
        port: 80
        type: ClusterIP
      setPermissions: true
      shutdown:
        terminationGracePeriodSeconds: 25
      topologySpreadConstraints: []
    testPods:
      affinity: {}
      annotations: {}
      image:
        permissionsTestContainer: debian:stable-slim
        statusTestContainer: alpine:latest
      labels: {}
      nodeSelector: {}
      resources: {}
      schedulerName: null
      tolerations: []
    tolerations: []
    updateStrategy: {}
    volumes:
      additional: []
      additionalSynchrony: []
      defaultPermissionsMode: 484
      localHome:
        customVolume: {}
        mountPath: /var/atlassian/application-data/confluence
        persistentVolumeClaim:
          create: false
          resources:
            requests:
              storage: 1Gi
          storageClassName: null
        persistentVolumeClaimRetentionPolicy:
          whenDeleted: null
          whenScaled: null
      sharedHome:
        customVolume: {}
        mountPath: /var/atlassian/application-data/shared-home
        nfsPermissionFixer:
          command: null
          enabled: true
          imageRepo: alpine
          imageTag: latest
          mountPath: /shared-home
          resources: {}
        persistentVolumeClaim:
          accessModes:
          - ReadWriteMany
          create: false
          resources:
            requests:
              storage: 1Gi
          storageClassName: null
        subPath: null
      synchronyHome:
        customVolume: {}
        mountPath: /var/atlassian/application-data/confluence
        persistentVolumeClaim:
          create: false
          resources:
            requests:
              storage: 1Gi
          storageClassName: null
        persistentVolumeClaimRetentionPolicy:
          whenDeleted: null
          whenScaled: null
---
# Source: confluence/templates/synchrony-start-script.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: unittest-confluence-synchrony-entrypoint
data:
  # The script we use as the entrypoint for the Synchrony container, because there isn't one we can use out of the box.
  # Note that the classpath ony really needs to contain synchrony-standalone.jar and the JDBC driver JAR, but for simplicitly
  # we just add every JAR in the Confluence lib directory.
  start-synchrony.sh: |
    #!/usr/bin/env bash
    java \
       -Xms1g \
       -Xmx2g \
       -Xss2048k \
       -Dsynchrony.port=8091 \
       -Dcluster.listen.port=5701 \
       -XX:ActiveProcessorCount=2 \
       -classpath /opt/atlassian/confluence/confluence/WEB-INF/packages/synchrony-standalone.jar:/opt/atlassian/confluence/confluence/WEB-INF/lib/* \
       synchrony.core \
       sql
---
# Source: confluence/templates/service-jmx.yaml
apiVersion: v1
kind: Service
metadata:
  name: unittest-confluence-jmx
  labels:
    helm.sh/chart: confluence-1.22.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "8.5.17"
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  type: ClusterIP
  ports:
    - port: 9999
      targetPort: jmx
      appProtocol: http
      name: jmx
  selector:
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
---
# Source: confluence/templates/service-synchrony.yaml
apiVersion: v1
kind: Service
metadata:
  name: unittest-confluence-synchrony
  labels:
    helm.sh/chart: confluence-1.22.0
    app.kubernetes.io/name: confluence-synchrony
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "8.5.17"
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
    - port: 5701
      targetPort: hazelcast
      protocol: TCP
      name: hazelcast
  selector:
    app.kubernetes.io/name: confluence-synchrony
    app.kubernetes.io/instance: unittest-confluence
---
# Source: confluence/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: unittest-confluence
  labels:
    helm.sh/chart: confluence-1.22.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "8.5.17"
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
    - port: 5701
      targetPort: hazelcast
      protocol: TCP
      name: hazelcast
  selector:
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
---
# Source: confluence/templates/statefulset-synchrony.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: unittest-confluence-synchrony
  labels:
    helm.sh/chart: confluence-1.22.0
    app.kubernetes.io/name: confluence-synchrony
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "8.5.17"
    app.kubernetes.io/managed-by: Helm
  annotations:
    argocd.argoproj.io/sync-wave: "10"
spec:
  replicas: 1
  serviceName: unittest-confluence-synchrony
  selector:
    matchLabels:
      app.kubernetes.io/name: confluence-synchrony
      app.kubernetes.io/instance: unittest-confluence
  template:
    metadata:
      annotations:
        checksum/config-jvm: 5c7e4f3183d49bd4e8c82a29b06246e551e4120042495652f1f9b27a0599a882
      labels:
        helm.sh/chart: confluence-1.22.0
        app.kubernetes.io/name: confluence-synchrony
        app.kubernetes.io/instance: unittest-confluence
        app.kubernetes.io/version: "8.5.17"
        app.kubernetes.io/managed-by: Helm
    spec:
      serviceAccountName: unittest-confluence
      terminationGracePeriodSeconds: 25
      securityContext:
        fsGroup: 2002
      hostAliases:
        - hostnames:
          - test.example.com
          ip: 192.168.1.1
      containers:
        - name: synchrony
          image: "atlassian/confluence:8.5.17"
          imagePullPolicy: IfNotPresent
          command: ["/scripts/start-synchrony.sh"]
          volumeMounts:
            - name: synchrony-home
              mountPath: "/var/atlassian/application-data/confluence"
            - mountPath: /scripts
              name: entrypoint-script
          ports:
            - name: http
              containerPort: 8091
              protocol: TCP
            - name: hazelcast
              containerPort: 5701
              protocol: TCP
          readinessProbe:
            httpGet:
              port: 8091
              path: /synchrony/heartbeat
            initialDelaySeconds: 5
            periodSeconds: 1
            failureThreshold: 10
          resources:
            requests:
              cpu: "2"
              memory: 2.5G
          env:
            - name: SET_PERMISSIONS
              value: "true"
            - name: SYNCHRONY_BIND
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: SYNCHRONY_SERVICE_URL
              value: "https:///synchrony"
      priorityClassName: high
      volumes:
        - name: entrypoint-script
          configMap:
            name: unittest-confluence-synchrony-entrypoint
            defaultMode: 484
        - name: synchrony-home
          emptyDir: {}
---
# Source: confluence/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: unittest-confluence
  labels:
    helm.sh/chart: confluence-1.22.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "8.5.17"
    app.kubernetes.io/managed-by: Helm
  annotations:
    argocd.argoproj.io/sync-wave: "10"
spec:
  replicas: 1
  serviceName: unittest-confluence
  selector:
    matchLabels:
      app.kubernetes.io/name: confluence
      app.kubernetes.io/instance: unittest-confluence
  template:
    metadata:
      annotations:
        checksum/config-jvm: 7bfc7d2515d63b68deb9827915f4a52f6ad5c0c621475dd37d812a664f993cd0
      labels:
        helm.sh/chart: confluence-1.22.0
        app.kubernetes.io/name: confluence
        app.kubernetes.io/instance: unittest-confluence
        app.kubernetes.io/version: "8.5.17"
        app.kubernetes.io/managed-by: Helm
    spec:
      serviceAccountName: unittest-confluence
      terminationGracePeriodSeconds: 25
      securityContext:
        fsGroup: 2002
      hostAliases:
        - hostnames:
          - test.example.com
          ip: 192.168.1.1
      initContainers:
        - name: nfs-permission-fixer
          image: alpine:latest
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 0 # make sure we run as root so we get the ability to change the volume permissions
          volumeMounts:
            - name: shared-home
              mountPath: "/shared-home"
          command: ["sh", "-c", "(chgrp 2002 /shared-home; chmod g+w /shared-home)"]
        - name: fetch-jmx-exporter
          image: bitnami/jmx-exporter:0.18.0
          command: ["cp"]
          args: ["/opt/bitnami/jmx-exporter/jmx_prometheus_javaagent.jar", "/var/atlassian/application-data/shared-home"]
          securityContext:
            runAsUser: 0
          volumeMounts:
            - mountPath: "/var/atlassian/application-data/shared-home"
              name: shared-home
      containers:
        - name: confluence
          image: "atlassian/confluence:8.5.17"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 8090
              protocol: TCP
            - name: hazelcast
              containerPort: 5701
              protocol: TCP
            - name: jmx
              containerPort: 9999
              protocol: TCP
          readinessProbe:
            httpGet:
              port: 8090
              path: /status
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 1
            failureThreshold: 6
          resources:
            requests:
              cpu: "2"
              memory: 2G
          volumeMounts:
            - name: local-home
              mountPath: "/var/atlassian/application-data/confluence"
            - name: local-home
              mountPath: "/opt/atlassian/confluence/logs"
              subPath: "logs"
            - name: shared-home
              mountPath: "/var/atlassian/application-data/shared-home"
            - name: helm-values
              mountPath: /opt/atlassian/helm
            - name: jmx-config
              mountPath: /opt/atlassian/jmx
          env:
            - name: ATL_TOMCAT_SCHEME
              value: "https"
            - name: ATL_TOMCAT_SECURE
              value: "true"
            - name: ATL_TOMCAT_PORT
              value: "8090"
            - name: ATL_TOMCAT_ACCESS_LOG
              value: "true"
            - name: UMASK
              value: "0022"
            - name: SET_PERMISSIONS
              value: "true"
            - name: ATL_PRODUCT_HOME_SHARED
              value: "/var/atlassian/application-data/shared-home"
            - name: JVM_SUPPORT_RECOMMENDED_ARGS
              valueFrom:
                configMapKeyRef:
                  key: additional_jvm_args
                  name: unittest-confluence-jvm-config
            - name: JVM_MINIMUM_MEMORY
              valueFrom:
                configMapKeyRef:
                  key: min_heap
                  name: unittest-confluence-jvm-config
            - name: JVM_MAXIMUM_MEMORY
              valueFrom:
                configMapKeyRef:
                  key: max_heap
                  name: unittest-confluence-jvm-config
            - name: JVM_RESERVED_CODE_CACHE_SIZE
              valueFrom:
                configMapKeyRef:
                  key: reserved_code_cache
                  name: unittest-confluence-jvm-config
            - name: CATALINA_OPTS
              value: "-javaagent:/var/atlassian/application-data/shared-home/jmx_prometheus_javaagent.jar=9999:/opt/atlassian/jmx/jmx-config.yaml"
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "/shutdown-wait.sh"]
      priorityClassName: high
      volumes:
        - name: local-home
          emptyDir: {}
        - name: shared-home
          emptyDir: {}
        - name: helm-values
          configMap:
            name: unittest-confluence-helm-values
        - name: jmx-config
          configMap:
            name: unittest-confluence-jmx-config
---
# Source: confluence/templates/tests/test-application-status.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "unittest-confluence-application-status-test"
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
  labels:
    helm.sh/chart: confluence-1.22.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "8.5.17"
    app.kubernetes.io/managed-by: Helm
spec:
  containers:
    - name: test
      image: alpine:latest
      env:
        - name: STATUS_URL
          value: "http://unittest-confluence:80/status"
      command:
        - /bin/sh
        - -ec
        - |
          apk add -q jq curl
          STATUS=$(curl -s "$STATUS_URL")
          echo "Verifying application state is RUNNING or FIRST_RUN: $STATUS"
          echo $STATUS | jq -e '.state|test("RUNNING|FIRST_RUN")'
  restartPolicy: Never
---
# Source: confluence/templates/tests/test-shared-home-permissions.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "unittest-confluence-shared-home-permissions-test"
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
  labels:
    helm.sh/chart: confluence-1.22.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "8.5.17"
    app.kubernetes.io/managed-by: Helm
spec:
  containers:
    - name: test
      image: debian:stable-slim
      imagePullPolicy: IfNotPresent
      securityContext:
        # We assume that the UID and GID used by the product images are the same, which in practice they are
        runAsUser: 2002
        runAsGroup: 2002
      volumeMounts:
        - name: shared-home
          mountPath: /shared-home
      command:
        - /bin/sh
        - -ec
        - |
          ls -ld /shared-home
          echo "Creating temporary file in shared home as user $(id -u):$(id -g)"
          touch /shared-home/permissions-test
          ls -l /shared-home/permissions-test
          rm /shared-home/permissions-test
  volumes:
    - name: shared-home
      emptyDir: {}
  restartPolicy: Never
