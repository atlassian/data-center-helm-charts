---
# Source: confluence/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: unittest-confluence
  labels:
    helm.sh/chart: confluence-0.14.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "7.12.3-jdk11"
    app.kubernetes.io/managed-by: Helm
---
# Source: confluence/templates/config-jvm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: unittest-confluence-jvm-config
  labels:
    helm.sh/chart: confluence-0.14.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "7.12.3-jdk11"
    app.kubernetes.io/managed-by: Helm
data:
  additional_jvm_args: >-
    -Dconfluence.cluster.hazelcast.listenPort=5701
    -Dsynchrony.service.url=/v1
    -Dsynchrony.by.default.enable.collab.editing.if.manually.managed=true
    -Dconfluence.clusterNodeName.useHostname=true
    -Datlassian.logging.cloud.enabled=false
    -XX:ActiveProcessorCount=2
  max_heap: 1g
  min_heap: 1g
  reserved_code_cache: 256m
---
# Source: confluence/templates/synchrony-start-script.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: unittest-confluence-synchrony-entrypoint
data:
  # The script we use as the entrypoint for the Synchrony container, because there isn't one we can use out of the box.
  # Note that the classpath ony really needs to contain synchrony-standalone.jar and the JDBC driver JAR, but for simplicitly
  # we just add every JAR in the Confluence lib directory.
  start-synchrony.sh: |
    #!/usr/bin/env bash
    java \
       -Xms1g \
       -Xmx2g \
       -Xss2048k \
       -XX:ActiveProcessorCount=2 \
       -classpath /opt/atlassian/confluence/confluence/WEB-INF/packages/synchrony-standalone.jar:/opt/atlassian/confluence/confluence/WEB-INF/lib/* \
       synchrony.core \
       sql
---
# Source: confluence/templates/service-synchrony.yaml
apiVersion: v1
kind: Service
metadata:
  name: unittest-confluence-synchrony
  labels:
    helm.sh/chart: confluence-0.14.0
    app.kubernetes.io/name: confluence-synchrony
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "7.12.3-jdk11"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
    - port: 5701
      targetPort: hazelcast
      protocol: TCP
      name: hazelcast
  selector:
    app.kubernetes.io/name: confluence-synchrony
    app.kubernetes.io/instance: unittest-confluence
---
# Source: confluence/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: unittest-confluence
  labels:
    helm.sh/chart: confluence-0.14.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "7.12.3-jdk11"
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
    - port: 5701
      targetPort: hazelcast
      protocol: TCP
      name: hazelcast
  selector:
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
---
# Source: confluence/templates/statefulset-synchrony.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: unittest-confluence-synchrony
  labels:
    helm.sh/chart: confluence-0.14.0
    app.kubernetes.io/name: confluence-synchrony
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "7.12.3-jdk11"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  serviceName: unittest-confluence-synchrony
  selector:
    matchLabels:
      app.kubernetes.io/name: confluence-synchrony
      app.kubernetes.io/instance: unittest-confluence
  template:
    metadata:
      labels:
        app.kubernetes.io/name: confluence-synchrony
        app.kubernetes.io/instance: unittest-confluence
    spec:
      serviceAccountName: unittest-confluence
      terminationGracePeriodSeconds: 1
      hostAliases:
      containers:
        - name: synchrony
          image: "atlassian/confluence-server:7.12.3-jdk11"
          imagePullPolicy: IfNotPresent
          command: ["/scripts/start-synchrony.sh"]
          volumeMounts:
            - mountPath: /scripts
              name: entrypoint-script
          ports:
            - name: http
              containerPort: 8091
              protocol: TCP
            - name: hazelcast
              containerPort: 5701
              protocol: TCP
          readinessProbe:
            httpGet:
              port: 8091
              path: /heartbeat
            initialDelaySeconds: 5
            periodSeconds: 1
            failureThreshold: 30
          resources:
            requests:
              cpu: "2"
              memory: 2.5G
          env:
            - name: SYNCHRONY_BIND
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: SYNCHRONY_SERVICE_URL
              value: 
      volumes:
        - name: entrypoint-script
          configMap:
            name: unittest-confluence-synchrony-entrypoint
            defaultMode: 0744
        - name: shared-home
          emptyDir: {}
---
# Source: confluence/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: unittest-confluence
  labels:
    helm.sh/chart: confluence-0.14.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "7.12.3-jdk11"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  serviceName: unittest-confluence
  selector:
    matchLabels:
      app.kubernetes.io/name: confluence
      app.kubernetes.io/instance: unittest-confluence
  template:
    metadata:
      labels:
        app.kubernetes.io/name: confluence
        app.kubernetes.io/instance: unittest-confluence
    spec:
      serviceAccountName: unittest-confluence
      terminationGracePeriodSeconds: 1
      securityContext:
        # This is intended to ensure that the shared-home volume is group-writeable by the GID used by the Confluence container.
        # However, this doesn't appear to work for NFS volumes due to a K8s bug: https://github.com/kubernetes/examples/issues/260
        fsGroup: 2002
      hostAliases:
      initContainers:
        - name: nfs-permission-fixer
          image: alpine
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 0 # make sure we run as root so we get the ability to change the volume permissions
          volumeMounts:
            - name: shared-home
              mountPath: "/shared-home"
          command: ["sh", "-c", "(chgrp 2002 /shared-home; chmod g+w /shared-home)"]
      containers:
        - name: confluence
          image: "atlassian/confluence-server:7.12.3-jdk11"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 8090
              protocol: TCP
            - name: hazelcast
              containerPort: 5701
              protocol: TCP
          readinessProbe:
            httpGet:
              port: 8090
              path: /status
            initialDelaySeconds: 10
            periodSeconds: 5
            failureThreshold: 30
          resources:
            requests:
              cpu: "2"
              memory: 2G
          volumeMounts:
            - name: local-home
              mountPath: "/var/atlassian/application-data/confluence"
            - name: local-home
              mountPath: "/opt/atlassian/confluence/logs"
              subPath: "logs"
            - name: shared-home
              mountPath: "/var/atlassian/application-data/shared-home"
          env:
            - name: ATL_TOMCAT_SCHEME
              value: "https"
            - name: ATL_TOMCAT_SECURE
              value: "true"
            - name: ATL_TOMCAT_ACCESS_LOG
              value: "true"
            - name: UMASK
              value: "0022"
            - name: SET_PERMISSIONS
              value: "false"
            - name: ATL_PRODUCT_HOME_SHARED
              value: "/var/atlassian/application-data/shared-home"
            - name: JVM_SUPPORT_RECOMMENDED_ARGS
              valueFrom:
                configMapKeyRef:
                  key: additional_jvm_args
                  name: unittest-confluence-jvm-config
            - name: JVM_MINIMUM_MEMORY
              valueFrom:
                configMapKeyRef:
                  key: min_heap
                  name: unittest-confluence-jvm-config
            - name: JVM_MAXIMUM_MEMORY
              valueFrom:
                configMapKeyRef:
                  key: max_heap
                  name: unittest-confluence-jvm-config
            - name: JVM_RESERVED_CODE_CACHE_SIZE
              valueFrom:
                configMapKeyRef:
                  key: reserved_code_cache
                  name: unittest-confluence-jvm-config
      volumes:
        - name: local-home
          emptyDir: {}
        - name: shared-home
          emptyDir: {}
---
# Source: confluence/templates/tests/test-application-status.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "unittest-confluence-application-status-test"
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
  labels:
    helm.sh/chart: confluence-0.14.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "7.12.3-jdk11"
    app.kubernetes.io/managed-by: Helm
spec:
  containers:
    - name: test
      image: alpine
      env:
        - name: STATUS_URL
          value: "http://unittest-confluence:80/status"
      command:
        - /bin/sh
        - -ec
        - |
          apk add -q jq curl
          STATUS=$(curl -s "$STATUS_URL")
          echo "Verifying application state is RUNNING or FIRST_RUN: $STATUS"
          echo $STATUS | jq -e '.state|test("RUNNING|FIRST_RUN")'
  restartPolicy: Never
---
# Source: confluence/templates/tests/test-shared-home-permissions.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "unittest-confluence-shared-home-permissions-test"
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
  labels:
    helm.sh/chart: confluence-0.14.0
    app.kubernetes.io/name: confluence
    app.kubernetes.io/instance: unittest-confluence
    app.kubernetes.io/version: "7.12.3-jdk11"
    app.kubernetes.io/managed-by: Helm
spec:
  containers:
    - name: test
      image: debian:stable-slim
      imagePullPolicy: IfNotPresent
      securityContext:
        # Slightly dodgy; we assume that the UID and GID used by the product images are the same, which in practice they are
        runAsUser: 2002
        runAsGroup: 2002
      volumeMounts:
        - name: shared-home
          mountPath: /shared-home
      command:
        - /bin/sh
        - -ec
        - |
          ls -ld /shared-home
          echo "Creating temporary file in shared home as user $(id -u):$(id -g)"
          touch /shared-home/permissions-test
          ls -l /shared-home/permissions-test
          rm /shared-home/permissions-test
  volumes:
    - name: shared-home
      emptyDir: {}
  restartPolicy: Never
